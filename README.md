# Assignment3_StreamingData
Project Title: Streaming Data Analysis System with Apache Kafka and MongoDB

Overview:
This project aims to implement a streaming data analysis system using Apache Kafka for real-time data processing and MongoDB for storing the results. The system consists of producers that stream data to Kafka topics, consumers that process the data using Apriori and PCY algorithms, and a MongoDB database for storing the insights generated by the consumers.

Setup Instructions:
1. Environment Setup:
   - Ensure that Apache Kafka and MongoDB are installed and running on your system.
   - Install any necessary dependencies for the producer and consumer applications.

2. Dataset Preparation and Pre-Processing:
   - Download the Amazon Metadata dataset and extract it.
   - Sample the dataset using the provided script.
   - Preprocess the sampled data to clean and format it for analysis.
   - Save the preprocessed data into a new JSON file.

3. Streaming Pipeline Setup:
   - Develop a producer application to stream data to Kafka topics.
   - Implement consumer applications for real-time analysis using Apriori and PCY algorithms.
   - Set up Kafka components like Kafka Connect and Zookeeper as needed.

4. Database Integration:
   - Choose MongoDB as the database for storing results.
   - Modify each consumer application to connect to MongoDB and store the analysis insights.

5. Bash Script :
   - Develop a Bash script to automate the execution of the producer, consumers, and Kafka components initialization.
